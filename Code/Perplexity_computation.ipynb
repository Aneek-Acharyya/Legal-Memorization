{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1319e1c8-1756-4520-8fa1-a7a0224f1b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir=\"/home/subinay/Documents/data/Probing/Memoriztion/results/mink%++/mink++_filter_results\"\n",
    "def compute_avg_perplexity(file_name):\n",
    "    json_path = open(f\"{dir}/{file_name}\")\n",
    "    data = json.load(json_path)\n",
    "    sentences_id=data.keys()\n",
    "    sentences_perplexity=[]\n",
    "    for sentence_id in sentences_id:\n",
    "        score=data[sentence_id][\"min_20_plus_plus\"]\n",
    "        sentences_perplexity.append(math.exp(-score))\n",
    "    average_perplexity = sum(sentences_perplexity) / len(sentences_perplexity)\n",
    "    return average_perplexity \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1c9fed6-7da8-46e0-90b5-a95ab1da57fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "mink_results_legal_dataset_IN_NON_MEMBER_16_gemma_2b.json_greater_avg.json\n",
      "4.636104639623982\n",
      "*******************************************\n",
      "mink_results_legal_dataset_IN_NON_MEMBER_32_gemma_2b.json_greater_avg.json\n",
      "4.36932566313246\n",
      "*******************************************\n",
      "mink_results_legal_dataset_UK_MEMBER_32_Llama-2-7b.json_greater_avg.json\n",
      "22.93551459105958\n",
      "*******************************************\n",
      "mink_results_legal_dataset_IN_NON_MEMBER_32_llama-2-13b.json_less_avg.json\n",
      "2.2158088021190115e+26\n",
      "*******************************************\n",
      "mink_results_legal_dataset_UK_MEMBER_16_gemma_2b.json_less_avg.json\n",
      "267599.71793440584\n",
      "*******************************************\n",
      "mink_results_legal_dataset_95_docs_IN_MEMBER_32_llama-2-13b.json_greater_avg.json\n",
      "22.622297352519123\n",
      "*******************************************\n",
      "mink_results_legal_dataset_UK_MEMBER_32_llama-2-13b.json_less_avg.json\n",
      "2159847145639.0054\n",
      "*******************************************\n",
      "mink_results_legal_dataset_IN_NON_MEMBER_16_llama-2-13b.json_greater_avg.json\n",
      "14.199761463319328\n",
      "*******************************************\n",
      "mink_results_legal_dataset_95_docs_IN_MEMBER_16_Llama-2-7b.json_greater_avg.json\n",
      "15.786398432234167\n",
      "*******************************************\n",
      "mink_results_legal_dataset_UK_MEMBER_32_llama-2-13b.json_greater_avg.json\n",
      "20.4539242137984\n",
      "*******************************************\n",
      "mink_results_legal_dataset_UK_MEMBER_16_Llama-2-7b.json_less_avg.json\n",
      "1.4651977051469203e+17\n",
      "*******************************************\n",
      "mink_results_legal_dataset_IN_NON_MEMBER_16_llama-2-13b.json_less_avg.json\n",
      "2.092472680834051e+45\n",
      "*******************************************\n",
      "mink_results_legal_dataset_UK_MEMBER_16_Llama-2-7b.json_greater_avg.json\n",
      "14.007447636511237\n",
      "*******************************************\n",
      "mink_results_legal_dataset_95_docs_IN_MEMBER_32_Llama-2-7b.json_less_avg.json\n",
      "2.366997028972637e+26\n",
      "*******************************************\n",
      "mink_results_legal_dataset_95_docs_IN_MEMBER_32_llama-2-13b.json_less_avg.json\n",
      "4.002628129169279e+44\n",
      "*******************************************\n",
      "mink_results_legal_dataset_UK_MEMBER_16_llama-2-13b.json_less_avg.json\n",
      "251058314521566.0\n",
      "*******************************************\n",
      "mink_results_legal_dataset_IN_NON_MEMBER_32_gemma_2b.json_less_avg.json\n",
      "10.939155708003739\n",
      "*******************************************\n",
      "mink_results_legal_dataset_IN_NON_MEMBER_32_Llama-2-7b.json_greater_avg.json\n",
      "22.249730064992786\n",
      "*******************************************\n",
      "mink_results_legal_dataset_UK_MEMBER_32_gemma_2b.json_greater_avg.json\n",
      "4.032256627467266\n",
      "*******************************************\n",
      "mink_results_legal_dataset_IN_NON_MEMBER_16_Llama-2-7b.json_less_avg.json\n",
      "8.398338505984835e+31\n",
      "*******************************************\n",
      "mink_results_legal_dataset_IN_NON_MEMBER_16_gemma_2b.json_less_avg.json\n",
      "56.6270447023674\n",
      "*******************************************\n",
      "mink_results_legal_dataset_95_docs_IN_MEMBER_16_gemma_2b.json_less_avg.json\n",
      "5612622854.495134\n",
      "*******************************************\n",
      "mink_results_legal_dataset_95_docs_IN_MEMBER_16_gemma_2b.json_greater_avg.json\n",
      "4.30387482195602\n",
      "*******************************************\n",
      "mink_results_legal_dataset_IN_NON_MEMBER_32_Llama-2-7b.json_less_avg.json\n",
      "2.064113546125629e+17\n",
      "*******************************************\n",
      "mink_results_legal_dataset_IN_NON_MEMBER_16_Llama-2-7b.json_greater_avg.json\n",
      "15.555218012789666\n",
      "*******************************************\n",
      "mink_results_legal_dataset_95_docs_IN_MEMBER_16_llama-2-13b.json_greater_avg.json\n",
      "14.23928086970483\n",
      "*******************************************\n",
      "mink_results_legal_dataset_UK_MEMBER_32_Llama-2-7b.json_less_avg.json\n",
      "1991515781185913.5\n",
      "*******************************************\n",
      "mink_results_legal_dataset_95_docs_IN_MEMBER_16_Llama-2-7b.json_less_avg.json\n",
      "2.7889871365026682e+47\n",
      "*******************************************\n",
      "mink_results_legal_dataset_95_docs_IN_MEMBER_32_gemma_2b.json_less_avg.json\n",
      "4153.400308931248\n",
      "*******************************************\n",
      "mink_results_legal_dataset_95_docs_IN_MEMBER_32_Llama-2-7b.json_greater_avg.json\n",
      "25.040121584456084\n",
      "*******************************************\n",
      "mink_results_legal_dataset_UK_MEMBER_32_gemma_2b.json_less_avg.json\n",
      "140.46532320477968\n",
      "*******************************************\n",
      "mink_results_legal_dataset_IN_NON_MEMBER_32_llama-2-13b.json_greater_avg.json\n",
      "20.424277601671886\n",
      "*******************************************\n",
      "mink_results_legal_dataset_95_docs_IN_MEMBER_16_llama-2-13b.json_less_avg.json\n",
      "1.964411336351725e+43\n",
      "*******************************************\n",
      "mink_results_legal_dataset_UK_MEMBER_16_llama-2-13b.json_greater_avg.json\n",
      "12.702041486524791\n",
      "*******************************************\n",
      "mink_results_legal_dataset_UK_MEMBER_16_gemma_2b.json_greater_avg.json\n",
      "3.991975891720616\n",
      "*******************************************\n",
      "mink_results_legal_dataset_95_docs_IN_MEMBER_32_gemma_2b.json_greater_avg.json\n",
      "4.280048615045293\n",
      "*******************************************\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "files=os.listdir(\"/home/subinay/Documents/data/Probing/Memoriztion/results/mink%++/mink++_filter_results\")\n",
    "print(len(files))\n",
    "for file in files:\n",
    "    average_perplexity=compute_avg_perplexity(file)\n",
    "    print(file)\n",
    "    print(average_perplexity)\n",
    "    print(\"*******************************************\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bd767148-035e-4b97-b4cc-8119ce9850e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Mink%++ computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8f6aaa2-0118-4797-a124-f146c0dc02bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir=\"/home/subinay/Documents/data/Probing/Memoriztion/statute_prediction/mink++\"\n",
    "import numpy as np\n",
    "import os\n",
    "def compute_avg_perplexity_per_model(file):\n",
    "    json_path=open(f\"{dir}/{file}\")\n",
    "    data=json.load(json_path)\n",
    "    sentences=data['detailed_results']\n",
    "    sentences_perplexity=[]\n",
    "    sentence_count=len(sentences)\n",
    "    for sentence in sentences:\n",
    "        score=sentence[\"min_20_plus_plus\"]\n",
    "        #sentences_perplexity.append(score)\n",
    "        sentences_perplexity.append(math.exp(-score))\n",
    "    #print(sentences_perplexity)\n",
    "    #max_value = max(sentences_perplexity)\n",
    "    #print(max_value)\n",
    "    threshold = 1000.0\n",
    "    average_perplexity = sum(sentences_perplexity) / len(sentences_perplexity)\n",
    "    filtered = [v for v in sentences_perplexity if v <= threshold]\n",
    "    average_perplexity=sum(filtered) / len(filtered)\n",
    "    le_count = sum(p <= average_perplexity for p in sentences_perplexity)\n",
    "    gt_count = sum(p > average_perplexity for p in sentences_perplexity)\n",
    "    return average_perplexity, sentence_count, le_count, gt_count \n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad1fa77a-b9e7-4c36-a5a1-496d7ef8e490",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir=\"/home/subinay/Documents/data/Probing/Memoriztion/statute_prediction/mink++\"\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "def main():\n",
    "    files=os.listdir(dir)\n",
    "    #files=files[0:1]\n",
    "    for file in files:\n",
    "        average_perplexity, sentences_count,le_count, gt_count  = compute_avg_perplexity_per_model(file)\n",
    "        print(file,\"***\",sentences_count, le_count, gt_count )\n",
    "        print(average_perplexity)\n",
    "        print(\"*********************************\")\n",
    "        \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "540059df-c72e-4817-9dd2-6a43b144f777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mink_results_statute_8_Member_Llama-2-7b.json.json *** 439 352 87\n",
      "45.62709329072099\n",
      "*********************************\n",
      "mink_results_statute_8_Member_llama-2-13b.json.json *** 439 349 90\n",
      "31.398594181902123\n",
      "*********************************\n",
      "mink%_results_statute_8_2024_Qwen-2-7B.json.json *** 287 232 55\n",
      "19.54962959802051\n",
      "*********************************\n",
      "mink%_results_statute_8_2024_llama-2-13b.json.json *** 287 234 53\n",
      "26.252108301043037\n",
      "*********************************\n",
      "mink%_results_statute_8_2024_gemma_2b.json.json *** 287 208 79\n",
      "15.174675828255166\n",
      "*********************************\n",
      "mink_results_statute_8_Member_Qwen-2-7B.json.json *** 439 362 77\n",
      "23.272994499697024\n",
      "*********************************\n",
      "mink_results_statute_8_Member_gemma_2b.json.json *** 439 357 82\n",
      "13.592129728997902\n",
      "*********************************\n",
      "mink%_results_statute_8_2024_Llama-2-7b.json.json *** 287 231 56\n",
      "42.85021266993018\n",
      "*********************************\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51308a4a-6ea0-41be-9804-b57d79a23cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17702\n"
     ]
    }
   ],
   "source": [
    "def count_sentences(file):\n",
    "    sentence_count=0\n",
    "    with open(f\"{dir}/{file}\",\"r\") as f1:\n",
    "        for line in f1:\n",
    "            sentence_count+=1\n",
    "    return sentence_count\n",
    "            \n",
    "        \n",
    "import os\n",
    "dir=\"/home/subinay/Documents/data/Probing/Memoriztion/IN_docs_test\"\n",
    "files=os.listdir(dir)\n",
    "total_sentence_count=0\n",
    "for file in files:\n",
    "    total_sentence_count+=count_sentences(file)\n",
    "print(total_sentence_count)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f51e8e5-a73c-4476-9f44-cc3aa00506cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Window Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4232b27-56ee-4205-a580-6ac18d881d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def compute_avg_perplexity_window(file):\n",
    "    json_path=open(f\"{dir}/{file}\")\n",
    "    sentences=json.load(json_path)\n",
    "    sentences_perplexity=[]\n",
    "    count_sentences=len(sentences)\n",
    "    for sentence in sentences:\n",
    "        score=int(sentence['perplexity'])\n",
    "        sentences_perplexity.append(score)\n",
    "    average_perplexity = sum(sentences_perplexity) / len(sentences_perplexity)\n",
    "    le_count = sum(p <= average_perplexity for p in sentences_perplexity)\n",
    "    gt_count = sum(p > average_perplexity for p in sentences_perplexity)\n",
    "    return average_perplexity, count_sentences, le_count, gt_count\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b34052a-7eb7-4db6-972f-af3ae76c1721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statute_8_Member_gemma_2b_results_complete.json 439 301 138\n",
      "218.2277904328018\n",
      "**********************************\n",
      "statute_8_2024_gemma_2b_results_complete.json 33 23 10\n",
      "273.06060606060606\n",
      "**********************************\n",
      "statute_8_Member_llama-2-13b_results_complete.json 439 292 147\n",
      "142.69476082004556\n",
      "**********************************\n",
      "statute_8_Member_Llama-2-7b_results_complete.json 439 306 133\n",
      "203.87927107061503\n",
      "**********************************\n",
      "statute_8_2024_Qwen-2-7B_results_complete.json 33 22 11\n",
      "270.8484848484849\n",
      "**********************************\n",
      "statute_8_Member_Qwen-2-7B_results_complete.json 439 308 131\n",
      "186.78359908883826\n",
      "**********************************\n",
      "statute_8_2024_Llama-2-7b_results_complete.json 33 21 12\n",
      "322.24242424242425\n",
      "**********************************\n",
      "statute_8_2024_llama-2-13b_results_complete.json 33 22 11\n",
      "234.27272727272728\n",
      "**********************************\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dir=\"/home/subinay/Documents/data/Probing/Memoriztion/statute_prediction/window/\"\n",
    "files=os.listdir(dir)\n",
    "for file in files:\n",
    "    average_perplexity, count_sentences, le_count, gt_count=compute_avg_perplexity_window(file)\n",
    "    print(file, count_sentences, le_count, gt_count)\n",
    "    print(average_perplexity)\n",
    "    print(\"**********************************\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c71b91e-c393-4354-9930-33d2625a2c92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
